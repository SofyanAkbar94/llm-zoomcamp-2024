{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d98dc19-145c-438c-b060-717d2a38f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1dc2405-49c4-4858-8996-f4ca51ead21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             answer_llm  \\\n",
      "0     You can sign up for the course by visiting the...   \n",
      "1     You can sign up using the link provided in the...   \n",
      "2     Yes, there is an FAQ for the Machine Learning ...   \n",
      "3     The context does not provide any specific info...   \n",
      "4     To structure your questions and answers for th...   \n",
      "...                                                 ...   \n",
      "1825  Some suggested titles for listing the Machine ...   \n",
      "1826  It is best advised that you do not list the Ma...   \n",
      "1827  You can incorporate your Machine Learning Zoom...   \n",
      "1828  The advice on including a project link in a CV...   \n",
      "1829  The suggestion to showcase progress through Li...   \n",
      "\n",
      "                                            answer_orig  document  \\\n",
      "0     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "1     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "2     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "3     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "4     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "...                                                 ...       ...   \n",
      "1825  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
      "1826  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
      "1827  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
      "1828  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
      "1829  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
      "\n",
      "                                               question  \\\n",
      "0                   Where can I sign up for the course?   \n",
      "1                    Can you provide a link to sign up?   \n",
      "2     Is there an FAQ for this Machine Learning course?   \n",
      "3     Does this course have a GitHub repository for ...   \n",
      "4     How can I structure my questions and answers f...   \n",
      "...                                                 ...   \n",
      "1825  What are some suggested titles for listing the...   \n",
      "1826  Should I list the Machine Learning Zoomcamp ex...   \n",
      "1827  In which LinkedIn sections can I incorporate m...   \n",
      "1828  Who gave advice on including a project link in...   \n",
      "1829  Who suggested showcasing progress through Link...   \n",
      "\n",
      "                         course  \n",
      "0     machine-learning-zoomcamp  \n",
      "1     machine-learning-zoomcamp  \n",
      "2     machine-learning-zoomcamp  \n",
      "3     machine-learning-zoomcamp  \n",
      "4     machine-learning-zoomcamp  \n",
      "...                         ...  \n",
      "1825  machine-learning-zoomcamp  \n",
      "1826  machine-learning-zoomcamp  \n",
      "1827  machine-learning-zoomcamp  \n",
      "1828  machine-learning-zoomcamp  \n",
      "1829  machine-learning-zoomcamp  \n",
      "\n",
      "[1830 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "github_url = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
    "\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aac45a5-f493-481d-bcc9-e973005a5dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            answer_llm  \\\n",
      "0    You can sign up for the course by visiting the...   \n",
      "1    You can sign up using the link provided in the...   \n",
      "2    Yes, there is an FAQ for the Machine Learning ...   \n",
      "3    The context does not provide any specific info...   \n",
      "4    To structure your questions and answers for th...   \n",
      "..                                                 ...   \n",
      "295  An alternative way to load the data using the ...   \n",
      "296  You can directly download the dataset from Git...   \n",
      "297  You can fetch data for homework using the `req...   \n",
      "298  If the status code is 200 when downloading dat...   \n",
      "299  If the file download fails when using the requ...   \n",
      "\n",
      "                                           answer_orig  document  \\\n",
      "0    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "1    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "2    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "3    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "4    Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
      "..                                                 ...       ...   \n",
      "295  Above users showed how to load the dataset dir...  8d209d6d   \n",
      "296  Above users showed how to load the dataset dir...  8d209d6d   \n",
      "297  Above users showed how to load the dataset dir...  8d209d6d   \n",
      "298  Above users showed how to load the dataset dir...  8d209d6d   \n",
      "299  Above users showed how to load the dataset dir...  8d209d6d   \n",
      "\n",
      "                                              question  \\\n",
      "0                  Where can I sign up for the course?   \n",
      "1                   Can you provide a link to sign up?   \n",
      "2    Is there an FAQ for this Machine Learning course?   \n",
      "3    Does this course have a GitHub repository for ...   \n",
      "4    How can I structure my questions and answers f...   \n",
      "..                                                 ...   \n",
      "295  What is an alternative way to load the data us...   \n",
      "296  How can I directly download the dataset from G...   \n",
      "297  Could you share a method to fetch data for hom...   \n",
      "298  What should I do if the status code is 200 whe...   \n",
      "299  What does the code using the requests library ...   \n",
      "\n",
      "                        course  \n",
      "0    machine-learning-zoomcamp  \n",
      "1    machine-learning-zoomcamp  \n",
      "2    machine-learning-zoomcamp  \n",
      "3    machine-learning-zoomcamp  \n",
      "4    machine-learning-zoomcamp  \n",
      "..                         ...  \n",
      "295  machine-learning-zoomcamp  \n",
      "296  machine-learning-zoomcamp  \n",
      "297  machine-learning-zoomcamp  \n",
      "298  machine-learning-zoomcamp  \n",
      "299  machine-learning-zoomcamp  \n",
      "\n",
      "[300 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.iloc[:300]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee1d0c1-b503-493e-aa9b-37fefb792e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f752f2925534ff19df09b4f98ffe943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-mpnet-base-dot-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd865ea437ec4e9c9d1f175024796c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3f3b31ce5148ee8446a27d61b2c358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b17a8ea2094469b88a66083a011d3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab59254707e48e2bf1120f5e6c443f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a9173899e34dbfa03a047e4bab49e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cc863fbaec45ee86628191c7e28105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce17cdb77a3441aaa1f5a3c2816efb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94114f8c8fc4a8eb9ffb6ba1381742e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f85e24be58405ea734913cea8a6452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b175d42620c461fa87003f7070e9bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "answer_llm = df.iloc[0].answer_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312a991-fe6a-4c93-94fe-04d6c16e8152",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd7a3f93-9ac8-43f6-a17a-382f773a57d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4224467\n"
     ]
    }
   ],
   "source": [
    "embedding = embedding_model.encode(answer_llm)\n",
    "first_value = embedding[0]\n",
    "print(first_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d2663-0d9b-4566-b676-4e81d537020d",
   "metadata": {},
   "source": [
    "## Q2. Computing the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9489724-17da-4762-876f-76fe96f34670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    embedding_orig = embedding_model.encode(row.answer_orig)\n",
    "    embedding_llm = embedding_model.encode(row.answer_llm)\n",
    "    \n",
    "    score = np.dot(embedding_orig, embedding_llm)\n",
    "    evaluations.append(score)\n",
    "\n",
    "percentile_75 = np.percentile(evaluations, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8f8bdc-4ce6-4955-a273-56547848686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.674309730529785\n"
     ]
    }
   ],
   "source": [
    "print(percentile_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ab57e-973b-45d6-ba11-7d8a28c81822",
   "metadata": {},
   "source": [
    "## Q3. Computing the cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c54cc44-13cc-4fed-9a9d-3a7c37a95122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d79efa-6137-42b5-958d-8f2fb091d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    embedding_orig = embedding_model.encode(row.answer_orig)\n",
    "    embedding_llm = embedding_model.encode(row.answer_llm)\n",
    "    \n",
    "    # Normalize the embeddings\n",
    "    embedding_orig_norm = normalize_vector(embedding_orig)\n",
    "    embedding_llm_norm = normalize_vector(embedding_llm)\n",
    "    \n",
    "    # Compute cosine similarity (dot product of normalized vectors)\n",
    "    score = np.dot(embedding_orig_norm, embedding_llm_norm)\n",
    "    evaluations.append(score)\n",
    "\n",
    "percentile_75 = np.percentile(evaluations, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35c51ff9-42ff-4d3c-b615-2432fdd892e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836234912276268\n"
     ]
    }
   ],
   "source": [
    "print(percentile_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729e784-c4f6-4a9a-82e6-39dbf0436006",
   "metadata": {},
   "source": [
    "## Q4. Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c1734a3-6e6b-4647-af9f-0ca563c35e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f20fe550-360e-41b3-8832-4c60e8779d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "# Get the answers at index 10\n",
    "r = df.iloc[10]\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge_scorer.get_scores(r['answer_orig'], r['answer_llm'])[0]\n",
    "\n",
    "# Extract the F1 score for rouge-1\n",
    "rouge_1_f1 = scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33878d9c-d033-4152-9ea5-cafb62377bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45454544954545456\n"
     ]
    }
   ],
   "source": [
    "print(rouge_1_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1030f76-de3f-4093-bd31-533ff9d83548",
   "metadata": {},
   "source": [
    "## Q5. Average rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6aa72b9-9cd1-40d7-a6cb-edba75def1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "# Get the answers at index 10\n",
    "r = df.iloc[10]\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge_scorer.get_scores(r['answer_orig'], r['answer_llm'])[0]\n",
    "\n",
    "# Extract F1 scores for rouge-1, rouge-2, and rouge-l\n",
    "rouge_1_f1 = scores['rouge-1']['f']\n",
    "rouge_2_f1 = scores['rouge-2']['f']\n",
    "rouge_l_f1 = scores['rouge-l']['f']\n",
    "\n",
    "# Compute the average\n",
    "average_rouge = (rouge_1_f1 + rouge_2_f1 + rouge_l_f1) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a3a145-3fe5-4c78-932c-0e2ac17c683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36500136000136507\n"
     ]
    }
   ],
   "source": [
    "print(average_rouge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b8e6e-380a-4b39-ae29-dfd662d208d8",
   "metadata": {},
   "source": [
    "## Q6. Average rouge score for all the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa376409-4992-4aa9-b755-481f25d063ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20696501983423318\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import pandas as pd\n",
    "\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "rouge_avg_scores = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    scores = rouge_scorer.get_scores(row['answer_orig'], row['answer_llm'])[0]\n",
    "    \n",
    "    rouge_1 = scores['rouge-1']['f']\n",
    "    rouge_2 = scores['rouge-2']['f']\n",
    "    rouge_l = scores['rouge-l']['f']\n",
    "    rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3\n",
    "    \n",
    "    rouge_1_scores.append(rouge_1)\n",
    "    rouge_2_scores.append(rouge_2)\n",
    "    rouge_l_scores.append(rouge_l)\n",
    "    rouge_avg_scores.append(rouge_avg)\n",
    "\n",
    "# Create a new dataframe with the scores\n",
    "rouge_df = pd.DataFrame({\n",
    "    'rouge_1': rouge_1_scores,\n",
    "    'rouge_2': rouge_2_scores,\n",
    "    'rouge_l': rouge_l_scores,\n",
    "    'rouge_avg': rouge_avg_scores\n",
    "})\n",
    "\n",
    "# Calculate the average of rouge_2 across all records\n",
    "average_rouge_2 = rouge_df['rouge_2'].mean()\n",
    "\n",
    "# Print average of rouge_2 across all records\n",
    "print(average_rouge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3e68f-e987-4273-ab33-21cae06b1a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
