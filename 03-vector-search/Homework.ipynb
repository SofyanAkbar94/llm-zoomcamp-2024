{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e795e2f-c29c-4190-8964-c0c975b392da",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2409c108-736d-4355-a4b3-ef9f3f39f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "0.078222655\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Fetching the documents\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "\n",
    "# Loading the model\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Creating the embedding for the user question\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "embedding = embedding_model.encode(user_question)\n",
    "\n",
    "# Retrieve the first value of the resulting vector\n",
    "first_value = embedding[0]\n",
    "print(first_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727306f9-f8e4-4ecd-ba3f-12b88c4a53be",
   "metadata": {},
   "source": [
    "## Q2. Creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b49e24d1-c5ba-495e-b96a-99a06c064447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(948, 768)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Fetching the documents\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "\n",
    "# Loading the model\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Create a list to hold the embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Iterate over each document to create embeddings for question and answer\n",
    "for doc in documents:\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qa_text = f'{question} {text}'\n",
    "    embedding = embedding_model.encode(qa_text)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Convert the list of embeddings to a numpy array\n",
    "X = np.array(embeddings)\n",
    "\n",
    "# Print the shape of the matrix X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c190d-8734-481f-ab78-751202341936",
   "metadata": {},
   "source": [
    "## Q3. Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e2614e1-2096-47f7-bf58-7933633de034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6506573\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Fetching the documents\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()\n",
    "\n",
    "# Loading the model\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Create a list to hold the embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Iterate over each document to create embeddings for question and answer\n",
    "for doc in documents:\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qa_text = f'{question} {text}'\n",
    "    embedding = embedding_model.encode(qa_text)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Convert the list of embeddings to a numpy array\n",
    "X = np.array(embeddings)\n",
    "\n",
    "# Create the embedding for the user question\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "v = embedding_model.encode(user_question)\n",
    "\n",
    "# Compute the cosine similarity scores\n",
    "scores = X.dot(v)\n",
    "\n",
    "# Find the highest score\n",
    "highest_score = np.max(scores)\n",
    "print(highest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b1ca6-2163-43e7-b977-5a42098dd68a",
   "metadata": {},
   "source": [
    "## Vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa9bd78b-74f7-43ec-8a0a-1b844e858639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'ee58a693'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '7842b56a'},\n",
       " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How can we contribute to the course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '2f19301f'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'a482086d'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'c02e79ef'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(v, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de82c6bc-275e-4493-b94d-61e500cb188f",
   "metadata": {},
   "source": [
    "## Q4. Hit-rate for our search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f575a2-8057-4e28-83b9-4cb325dbd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -it \\\n",
    "#     --rm \\\n",
    "#     --name elasticsearch \\\n",
    "#     -p 9200:9200 \\\n",
    "#     -p 9300:9300 \\\n",
    "#     -e \"discovery.type=single-node\" \\\n",
    "#     -e \"xpack.security.enabled=false\" \\\n",
    "#     docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3117208d-0d35-4873-8a00-d5eb574c00e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '7d2aec048f7e', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'uKMEKEiqRCer0R_X0lFQ-w', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0779af0d-4f76-4ef8-9738-49a1581381c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load documents\n",
    "with open('eval/documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Initialize Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "# Define index settings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "# Recreate index\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84886ca7-7536-4d99-aec6-314f42f92a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 948/948 [03:26<00:00,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Index documents\n",
    "for doc in tqdm(documents):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qt = question + ' ' + text\n",
    "\n",
    "    doc['question_vector'] = embedding_model.encode(question)\n",
    "    doc['text_vector'] = embedding_model.encode(text)\n",
    "    doc['question_text_vector'] = embedding_model.encode(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb903b78-a833-4a3e-afb3-fd8c2cdd557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 948/948 [00:19<00:00, 47.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e1409f5-4909-40ed-a3cf-fe02f5c22935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for k-NN search\n",
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e53966e5-7fda-4dd5-92ec-37826a8acae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = embedding_model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4e19591-8316-4216-83e2-d2de7c78d38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '0227b872'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth = pd.read_csv('eval/ground-truth-data.csv')\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "367dfa63-6a88-4f66-b3fa-3dd3cbe55df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa436604-98ac-4fd6-aae7-3f15855a7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b42507fc-d881-4130-b3ab-d240cbb1d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "356ced59-fa22-4427-929e-5f7567d4852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for question vector search using VectorSearchEngine\n",
    "def question_vector_search(q):\n",
    "    question = q['question']\n",
    "    v_q = embedding_model.encode(question)\n",
    "    return search_engine.search(v_q, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a06e65ab-63dd-4a51-a51b-4c7de34e9b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1830/1830 [02:18<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 0.9218579234972678\n",
      "MRR: 0.8202459016393446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the search engine\n",
    "evaluation_results = evaluate(ground_truth, question_vector_search)\n",
    "print(f\"Hit rate: {evaluation_results['hit_rate']}\")\n",
    "print(f\"MRR: {evaluation_results['mrr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff7dbc-92ad-4422-a688-c37a8bf8838d",
   "metadata": {},
   "source": [
    "## Q5. Indexing with Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79c43e71-f9be-451b-b646-0ab0166c680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID with the highest score: ee58a693\n"
     ]
    }
   ],
   "source": [
    "# Perform a k-NN search using the same query from user_question\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "v_query = embedding_model.encode(user_question)\n",
    "\n",
    "def elastic_search_knn(field, vector, course=None):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000\n",
    "    }\n",
    "    if course:\n",
    "        knn[\"filter\"] = {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "# Search for the user question\n",
    "results = elastic_search_knn('question_vector', v_query)\n",
    "highest_score_doc_id = results[0]['id']\n",
    "print(f\"Document ID with the highest score: {highest_score_doc_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54c8ac-8c8e-4f61-9708-d91e3aa5cdfb",
   "metadata": {},
   "source": [
    "## Q6. Hit-rate for Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e25d76e5-75ee-4740-913d-15d2a47d5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1830/1830 [01:12<00:00, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate for Elasticsearch: 0.8076502732240437\n",
      "MRR for Elasticsearch: 0.6985519125683067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function for question vector search using Elasticsearch\n",
    "def question_vector_search_elastic(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "    v_q = embedding_model.encode(question)\n",
    "    return elastic_search_knn('question_vector', v_q, course)\n",
    "\n",
    "# Evaluate the Elasticsearch-based search engine\n",
    "evaluation_results_elastic = evaluate(ground_truth, question_vector_search_elastic)\n",
    "print(f\"Hit rate for Elasticsearch: {evaluation_results_elastic['hit_rate']}\")\n",
    "print(f\"MRR for Elasticsearch: {evaluation_results_elastic['mrr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedb2f3-fde6-4b11-9d12-8191a117e683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
